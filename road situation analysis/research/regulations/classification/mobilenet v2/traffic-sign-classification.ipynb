{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade albumentations -q\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFile\n",
    "import glob\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image  \n",
    "\n",
    "import albumentations as A\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.layers\n",
    "from tensorflow.keras.layers import Dense, ReLU\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_plot_from_history(history, metric, n_epochs, stage):\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    plt.plot(np.arange(0, n_epochs), history.history[metric], label=\"train_%s\" % metric)\n",
    "    if \"val_%s\" % metric in history.history:\n",
    "        plt.plot(np.arange(0, n_epochs), history.history[\"val_%s\" % metric], label=\"val_%s\" % metric)\n",
    "    title = stage + '_%s' % metric\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.legend()\n",
    "    filename = title + '.png'\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data, batch_size, augmentation, image_size, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.augmentation = augmentation\n",
    "        self.shuffle = shuffle\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.image_names = np.array([item['path'] for item in data])\n",
    "        self.targets = to_categorical(np.array([int(item['label'][1:]) for item in data]))\n",
    "        self.samples = len(self.targets)\n",
    "\n",
    "        self.indexes = np.arange(self.samples)\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.samples / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def transform_image(self, image):\n",
    "        image = cv2.resize(image, (self.image_size, self.image_size), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        if self.augmentation:\n",
    "            image = self.augmentation(image=image)['image']\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        take_ind = self.indexes[index * self.batch_size: min((index + 1) * self.batch_size, len(self.targets))]\n",
    "        X = np.empty((len(take_ind), self.image_size, self.image_size, 3))\n",
    "        y = self.targets[take_ind, :]\n",
    "\n",
    "        for i in range(len(take_ind)):\n",
    "            img = cv2.imread(self.image_names[take_ind[i]], cv2.IMREAD_COLOR)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = self.transform_image(img)\n",
    "            X[i] = img\n",
    "            \n",
    "        X = preprocess_input(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create augmentations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=30, \n",
    "                           p=0.5, border_mode=cv2.BORDER_CONSTANT), \n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.RGBShift(p=0.25),\n",
    "        A.GaussNoise(p=0.25),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"../input/acc-german-traffic-sign-classification/GTSRB_Challenge/train\"\n",
    "TEST_DIR = \"../input/acc-german-traffic-sign-classification/GTSRB_Challenge/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = 48\n",
    "BATCH_SIZE = 32\n",
    "num_classes = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "label_stat = []\n",
    "\n",
    "for label in os.listdir(TRAIN_DIR):\n",
    "    for img_path in glob.glob(os.path.join(TRAIN_DIR, label, \"*.ppm\")):\n",
    "        train_data.append({'path': img_path, 'label': label})\n",
    "        label_stat.append(label)\n",
    "\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=label_stat, shuffle=True)\n",
    "\n",
    "train_generator = DataGenerator(train_data, BATCH_SIZE, transform, INPUT_SHAPE)\n",
    "validation_generator = DataGenerator(val_data, BATCH_SIZE, None, INPUT_SHAPE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(INPUT_SHAPE, INPUT_SHAPE, 3))\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(INPUT_SHAPE, INPUT_SHAPE, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warmup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 3\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "851/980 [=========================>....] - ETA: 15s - loss: 2.5969 - accuracy: 0.3087"
     ]
    }
   ],
   "source": [
    "opt = Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // BATCH_SIZE,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_generator.samples // BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS, verbose=1)\n",
    "\n",
    "draw_plot_from_history(history, 'loss', NUM_EPOCHS, 'STAGE_1')\n",
    "draw_plot_from_history(history, 'accuracy', NUM_EPOCHS, 'STAGE_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model3_stage1.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfreezeing deeper layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 0.0003\n",
    "FINE_TUNE_FROM_LAYER = -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[FINE_TUNE_FROM_LAYER:]:\n",
    "    if not isinstance(layer, tensorflow.keras.layers.BatchNormalization):\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=LEARNING_RATE,\n",
    "    decay_steps=NUM_EPOCHS * train_generator.samples // BATCH_SIZE,\n",
    "    end_learning_rate=LEARNING_RATE / 10,\n",
    "    power=1.0)\n",
    "\n",
    "opt = Adam(learning_rate=learning_rate_fn)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "save_best_checkpoint = ModelCheckpoint(\"model3_stage2.hdf5\", verbose=1, monitor='val_loss', save_best_only=True, mode='auto')\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // BATCH_SIZE,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_generator.samples // BATCH_SIZE,\n",
    "    epochs = NUM_EPOCHS,\n",
    "    callbacks=[save_best_checkpoint], \n",
    "    verbose=1)\n",
    "\n",
    "draw_plot_from_history(history, 'loss', NUM_EPOCHS, 'STAGE_2')\n",
    "draw_plot_from_history(history, 'accuracy', NUM_EPOCHS, 'STAGE_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_plot_from_history(history, metric, n_epochs, stage):\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure(figsize=(21, 15))\n",
    "    plt.plot(np.arange(0, n_epochs), history.history[metric], label=\"train_%s\" % metric)\n",
    "    if \"val_%s\" % metric in history.history:\n",
    "        plt.plot(np.arange(0, n_epochs), history.history[\"val_%s\" % metric], label=\"val_%s\" % metric)\n",
    "    title = metric\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.xlabel(\"Epoch #\", fontsize=18)\n",
    "    plt.ylabel(\"Value\", fontsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    filename = title + '.png'\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_plot_from_history(history, 'loss', NUM_EPOCHS, 'STAGE_2')\n",
    "save_plot_from_history(history, 'accuracy', NUM_EPOCHS, 'STAGE_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(model, test_img_dir):\n",
    "\n",
    "    result = dict()\n",
    "    keys = ['name', *['c%d' % i for i in range(10)]]\n",
    "    for key in keys:\n",
    "        result[key] = []\n",
    "        \n",
    "    paths = sorted(list(os.listdir(test_img_dir)))\n",
    "\n",
    "    for path in tqdm(paths):\n",
    "        if not path.endswith('.jpg'):\n",
    "            continue\n",
    "        \n",
    "        image = cv2.imread(os.path.join(test_img_dir, path), cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (INPUT_SHAPE, INPUT_SHAPE), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        pred = model.predict(np.expand_dims(image, 0))[0]\n",
    "        result['name'].append(path)\n",
    "        for i in range(10):\n",
    "            result['c%d' % i].append(pred[i])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('model3_stage2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = classify(model, TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dct = {'img': result['name']}\n",
    "for i in range(10):\n",
    "    col = 'c%d' % i\n",
    "    dct[col] = result[col]\n",
    "    \n",
    "df = pd.DataFrame(dct)\n",
    "df.to_csv('submission.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve score a bit with clipping hack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df.copy()\n",
    "\n",
    "cols = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "arr, names = df_new.values[:, 1:], df_new.values[:, 0]\n",
    "arr = np.clip(arr, 0.025, 0.975)\n",
    "arr /= np.sum(arr, axis=1, keepdims=True)\n",
    "\n",
    "new_df = pd.DataFrame(np.hstack([names.reshape((-1, 1)), arr]), columns=df.columns)\n",
    "new_df.to_csv('submission_new.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
